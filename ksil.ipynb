{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "qP8VBZtvHrqG",
        "-YpE-cqtKAyt"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### K-Sil Clustering"
      ],
      "metadata": {
        "id": "BEcmF2LdHic3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6etVEpKyHUvI"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "from joblib import Parallel, delayed\n",
        "\n",
        "class KSil:\n",
        "    def __init__(self,\n",
        "                 n_clusters=3,\n",
        "                 init='random',\n",
        "                 max_iter=100,\n",
        "                 random_state=0,\n",
        "                 init_temperature=1.0,\n",
        "                 learning_rate=0.2,\n",
        "                 tol=1e-4,\n",
        "                 n_init=1, n_jobs=1):\n",
        "\n",
        "        # Parameters\n",
        "        self.n_clusters = int(n_clusters)     # Number of clusters\n",
        "        self.init = init                      # Initialization method\n",
        "        self.max_iter = int(max_iter)         # Maximum number of iterations\n",
        "        self.init_temperature = float(init_temperature) # Initial temperature\n",
        "        self.random_state = int(random_state) # Random seed\n",
        "        self.learning_rate = learning_rate    # Learning rate for temperature\n",
        "        self.tol = float(tol)                 # Centroid convergence tolerance\n",
        "\n",
        "        # For multiple initializations:\n",
        "        self.n_init = n_init                  # Number of initializations\n",
        "        self.n_jobs = n_jobs                  # Number of cores\n",
        "\n",
        "        # n_clusters check\n",
        "        if self.n_clusters < 2:\n",
        "           raise ValueError(f\"n_clusters ({self.n_clusters}) must be > 1.\")\n",
        "        # init check\n",
        "        if isinstance(self.init, str) and self.init not in ('random', 'k-means++'):\n",
        "           raise ValueError(f\"init ({self.init}) must be 'random' or 'k-means++'.\")\n",
        "        # n_init check\n",
        "        if self.n_init < 1:\n",
        "           raise ValueError(f\"n_init ({self.n_init}) must be > 0.\")\n",
        "\n",
        "        # Attributes\n",
        "        self.labels_ = None          # Cluster labels (converged partition)\n",
        "        self.cluster_centers_ = None # Cluster centers (converged partition)\n",
        "        self.n_iter_ = None          # Number of iterations (until convergence)\n",
        "        self.sil_ = None             # silhouette (centroid-approximated) at converged partition\n",
        "\n",
        "        # history attributes\n",
        "        self.centers_history_ = None # Centroids across iterations\n",
        "        self.labels_history_ = None  # Assignments across iterations\n",
        "        self.sil_history_ = None     # Silhouette proxy across iterations\n",
        "        self.weights_history_ = None # Weights across iterations\n",
        "\n",
        "    def _initialization(self, X, n_clusters):\n",
        "        X = np.asarray(X)\n",
        "        if X.shape[0] < n_clusters:\n",
        "           raise ValueError(f\"n_clusters ({n_clusters}) can not exceed n_samples ({X.shape[0]}).\")\n",
        "\n",
        "        kmeans = KMeans(n_clusters=n_clusters,\n",
        "                        init=self.init,\n",
        "                        random_state=self.random_state,\n",
        "                        n_init=1,\n",
        "                        max_iter=1).fit(X)\n",
        "        centers = kmeans.cluster_centers_\n",
        "        labels = kmeans.labels_\n",
        "\n",
        "        # Retry if some clusters are empty in the initial assignment\n",
        "        if np.unique(labels).size < n_clusters:\n",
        "           max_retries = 10 # 10 retries at max\n",
        "           base_seed = self.random_state\n",
        "           for attempt in range(1, max_retries + 1):\n",
        "               seed = base_seed + attempt\n",
        "               km = KMeans(n_clusters=n_clusters,\n",
        "                           init=self.init,\n",
        "                           random_state=seed,\n",
        "                           n_init=1,\n",
        "                           max_iter=1).fit(X)\n",
        "               centers = km.cluster_centers_\n",
        "               labels = km.labels_\n",
        "               if np.unique(labels).size == n_clusters:\n",
        "                  break\n",
        "           else:\n",
        "               raise ValueError(\n",
        "                     f\"KMeans (1-iter) initialization produced empty clusters after {max_retries} retries. \"\n",
        "                     f\"Try a different random_state, or init='k-means++'.\")\n",
        "        return centers, labels\n",
        "\n",
        "    def _fit_once(self, X, n_clusters, previous_centers, w):\n",
        "        X = np.asarray(X)\n",
        "        w = np.asarray(w)\n",
        "        km = KMeans(\n",
        "             n_clusters=n_clusters,\n",
        "             init=previous_centers,\n",
        "             n_init=1,\n",
        "             max_iter=1,\n",
        "             random_state=self.random_state)\n",
        "        km.fit(X, sample_weight=w)\n",
        "\n",
        "        centers = km.cluster_centers_\n",
        "        labels = km.labels_\n",
        "        return centers, labels\n",
        "\n",
        "    @staticmethod\n",
        "    def sil_scores(X, labels, centers):\n",
        "        X = np.asarray(X, dtype=float)\n",
        "        labels = np.asarray(labels, dtype=int)\n",
        "        centers = np.asarray(centers, dtype=float)\n",
        "\n",
        "        if len(X) == 0:\n",
        "           raise ValueError(\"X is empty. Cannot compute silhouette scores.\")\n",
        "\n",
        "        n = X.shape[0]\n",
        "\n",
        "        # Squared distances to all centroids\n",
        "        D = euclidean_distances(X, centers, squared=True)\n",
        "\n",
        "        # Distance to own centroid (a: intra cluster distance proxy)\n",
        "        D_diag = D[np.arange(n), labels]  # a^2\n",
        "        a_vals = np.sqrt(D_diag)  # a\n",
        "\n",
        "        # Nearest other centroid distance (b: inter cluster distance)\n",
        "        D_others = D.copy()\n",
        "        D_others[np.arange(n), labels] = np.inf\n",
        "        b_sq = D_others.min(axis=1)  # b^2\n",
        "        b_vals = np.sqrt(b_sq)  # b\n",
        "\n",
        "        # Silhouette surrogate (b-a)/[max{a,b}+epsilon]\n",
        "        max_ab = np.maximum(np.maximum(a_vals, b_vals), 1e-12)\n",
        "        s_vals = (b_vals - a_vals) / max_ab\n",
        "\n",
        "        return s_vals, a_vals, b_vals\n",
        "\n",
        "    @staticmethod\n",
        "    def micro_sil(s_vals):\n",
        "        s_vals = np.asarray(s_vals, dtype=float)\n",
        "        if s_vals.size == 0:\n",
        "           return 0.0\n",
        "        return float(s_vals.mean())\n",
        "\n",
        "    @staticmethod\n",
        "    def macro_sil(s_vals, labels):\n",
        "        s_vals = np.asarray(s_vals, dtype=float)\n",
        "        labels = np.asarray(labels, dtype=int)\n",
        "\n",
        "        if s_vals.size == 0 or labels.size == 0:\n",
        "           return 0.0\n",
        "\n",
        "        uniq, inv = np.unique(labels, return_inverse=True)\n",
        "        if uniq.size == 0:\n",
        "           return 0.0\n",
        "        sum_per_cluster = np.bincount(inv, weights=s_vals)\n",
        "        cnt_per_cluster = np.bincount(inv)\n",
        "\n",
        "        valid = cnt_per_cluster > 0\n",
        "        if not np.any(valid):\n",
        "           return 0.0\n",
        "        cluster_means = sum_per_cluster[valid] / cnt_per_cluster[valid]\n",
        "        return float(cluster_means.mean())\n",
        "\n",
        "    def _weights(self, s_vals, temperature):\n",
        "        s_vals = np.asarray(s_vals, dtype=float)\n",
        "        weights = np.exp(s_vals * temperature)\n",
        "        return weights\n",
        "\n",
        "    def _KSil(self, X, n_clusters, max_iter):\n",
        "\n",
        "        # Initialize centroids\n",
        "        centers, labels = self._initialization(X, n_clusters)\n",
        "        tau = self.init_temperature # initial temperature\n",
        "        prev_score =  None\n",
        "\n",
        "        centers_history = [centers.copy()]\n",
        "        labels_history = [labels.copy()]\n",
        "        sil_history = []\n",
        "        weights_history = []\n",
        "\n",
        "        n_iter = 0\n",
        "\n",
        "        while n_iter < max_iter:\n",
        "\n",
        "            n_iter += 1\n",
        "\n",
        "            # Compute point-silhouette scores\n",
        "            sil_vals, a_vals, b_vals = KSil.sil_scores(X, labels, centers)\n",
        "            score = KSil.macro_sil(sil_vals, labels)\n",
        "\n",
        "            micro_sil = KSil.micro_sil(sil_vals)\n",
        "            sil_history.append(micro_sil)\n",
        "\n",
        "            # Update temperature\n",
        "            if prev_score is not None:\n",
        "               r = (score - prev_score) / max(1 - prev_score, 1e-12)\n",
        "\n",
        "               r = float(np.clip(r, -1.0, 1.0))\n",
        "\n",
        "               # data-driven bounds to avoid softmax saturation\n",
        "               counts = np.bincount(labels, minlength=n_clusters)\n",
        "               m_max = int(max(counts.max(), 2))\n",
        "               L     = float(np.sqrt(2.0 * np.log(m_max)))\n",
        "               z_max = (m_max - 1) / m_max\n",
        "               tau_min, tau_max = 1e-12, L / max(z_max, 1e-8)\n",
        "\n",
        "               # multiplicative update (no logs needed)\n",
        "               eta = self.learning_rate # default: 0.2 (small stable learning rate)\n",
        "\n",
        "               # Update temperature based on the rate of change of the silhouette objective\n",
        "               tau = float(np.clip(tau * np.exp(eta * r), tau_min, tau_max))\n",
        "\n",
        "            # store for next iteration’s drift calc\n",
        "            prev_score = score\n",
        "\n",
        "            # Retain previous centroids for convergence checking\n",
        "            previous_centers = centers.copy()\n",
        "\n",
        "            # Compute weights based on silhouette scores\n",
        "            weights = self._weights(sil_vals, tau)\n",
        "\n",
        "            weights_history.append(weights.copy())\n",
        "\n",
        "            # Update centroids and assignments\n",
        "            centers, labels = self._fit_once(X, n_clusters, previous_centers, weights)\n",
        "\n",
        "            centers_history.append(centers.copy())\n",
        "            labels_history.append(labels.copy())\n",
        "\n",
        "            avg_move = np.linalg.norm(centers - previous_centers, axis=1).mean()\n",
        "\n",
        "            # Centroid stability\n",
        "            if avg_move < self.tol:\n",
        "               break\n",
        "\n",
        "        return centers, labels, n_iter, sil_history, centers_history, labels_history, weights_history\n",
        "\n",
        "    def fit(self, X):\n",
        "        \"\"\"\n",
        "        Run KSil on X and store the converged partition.\n",
        "        X: array-like, shape (n_samples, n_features)\n",
        "        \"\"\"\n",
        "        X_arr = X.values if hasattr(X, \"values\") else np.asarray(X, dtype=float)\n",
        "\n",
        "        if self.n_init == 1:\n",
        "           (centers,\n",
        "           labels,\n",
        "           n_iter,\n",
        "           sil_history,\n",
        "           centers_history,\n",
        "           labels_history,\n",
        "           weights_history) = self._KSil(X_arr, self.n_clusters, self.max_iter)\n",
        "        else:\n",
        "           base_seed = self.random_state\n",
        "           seeds = [int(base_seed) + i for i in range(self.n_init)]\n",
        "\n",
        "           # Helper: directly call _KSil with a seed\n",
        "           def _run_one(seed):\n",
        "               self.random_state = seed\n",
        "               return self._KSil(X_arr, self.n_clusters, self.max_iter)\n",
        "\n",
        "           if self.n_jobs in (None, 1):\n",
        "              results = [_run_one(seed) for seed in seeds]\n",
        "           else:\n",
        "              results = Parallel(n_jobs=self.n_jobs)(delayed(_run_one)(seed) for seed in seeds)\n",
        "\n",
        "           # Pick best run by final silhouette\n",
        "           best_idx = None\n",
        "           best_sil = -np.inf\n",
        "\n",
        "           for i, res in enumerate(results):\n",
        "               (_, _, _, sil_history_i,\n",
        "               _, _, _) = res\n",
        "               if sil_history_i:\n",
        "                  final_sil_i = sil_history_i[-1]\n",
        "               else:\n",
        "                  final_sil_i = -np.inf\n",
        "               if final_sil_i > best_sil:\n",
        "                   best_sil = final_sil_i\n",
        "                   best_idx = i\n",
        "\n",
        "           (centers,\n",
        "           labels,\n",
        "           n_iter,\n",
        "           sil_history,\n",
        "           centers_history,\n",
        "           labels_history,\n",
        "           weights_history) = results[best_idx]\n",
        "\n",
        "           self.random_state = base_seed # restore base random_state\n",
        "\n",
        "        self.cluster_centers_ = centers\n",
        "        self.labels_ = labels\n",
        "        self.n_iter_ = n_iter\n",
        "\n",
        "        self.sil_history_ = sil_history\n",
        "        self.sil_ = sil_history[-1] if sil_history else None\n",
        "        self.centers_history_ = centers_history\n",
        "        self.labels_history_ = labels_history\n",
        "        self.weights_history_ = weights_history\n",
        "\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        Assign new points to the nearest learned centroid.\n",
        "        \"\"\"\n",
        "        if self.cluster_centers_ is None:\n",
        "           raise ValueError(\"KSil model is not fitted yet. Call '.fit(...)' first.\")\n",
        "\n",
        "        X_arr = X.values if hasattr(X, \"values\") else np.asarray(X, dtype=float)\n",
        "        dist_matrix = euclidean_distances(X_arr, self.cluster_centers_, squared=True)\n",
        "        labels = np.argmin(dist_matrix, axis=1)\n",
        "        return labels.astype(int)\n",
        "\n",
        "    def transform(self, X):\n",
        "        \"\"\"\n",
        "        Return distances of each sample to each centroid.\n",
        "        \"\"\"\n",
        "        if self.cluster_centers_ is None:\n",
        "           raise ValueError(\"KSil model is not fitted yet. Call '.fit(...)' first.\")\n",
        "\n",
        "        X_arr = X.values if hasattr(X, \"values\") else np.asarray(X, dtype=float)\n",
        "        distances = euclidean_distances(X_arr, self.cluster_centers_, squared=False)\n",
        "        return distances\n",
        "\n",
        "    def fit_predict(self, X):\n",
        "        \"\"\"\n",
        "        Equivalent to: fit(X); return labels_.\n",
        "        \"\"\"\n",
        "        self.fit(X)\n",
        "        return self.labels_\n",
        "\n",
        "    def fit_transform(self, X):\n",
        "        \"\"\"\n",
        "        Equivalent to: fit(X); return transform(X).\n",
        "        \"\"\"\n",
        "        self.fit(X)\n",
        "        return self.transform(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### K-Sil with empty cluster re-initialization"
      ],
      "metadata": {
        "id": "qP8VBZtvHrqG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "from joblib import Parallel, delayed\n",
        "\n",
        "class KSil_ecr:\n",
        "    def __init__(self,\n",
        "                 n_clusters=3,\n",
        "                 init='random',\n",
        "                 max_iter=100,\n",
        "                 random_state=0,\n",
        "                 init_temperature=1.0,\n",
        "                 learning_rate=0.2,\n",
        "                 tol=1e-4,\n",
        "                 n_init=1, n_jobs=1):\n",
        "\n",
        "        # Parameters\n",
        "        self.n_clusters = int(n_clusters)     # Number of clusters\n",
        "        self.init = init                      # Initialization method\n",
        "        self.max_iter = int(max_iter)         # Maximum number of iterations\n",
        "        self.init_temperature = float(init_temperature) # Initial temperature\n",
        "        self.random_state = int(random_state) # Random seed\n",
        "        self.learning_rate = learning_rate    # Learning rate for temperature\n",
        "        self.tol = float(tol)                 # Centroid convergence tolerance\n",
        "\n",
        "        # For multiple initializations:\n",
        "        self.n_init = n_init                  # Number of initializations\n",
        "        self.n_jobs = n_jobs                  # Number of cores\n",
        "\n",
        "        # n_clusters check\n",
        "        if self.n_clusters < 2:\n",
        "           raise ValueError(f\"n_clusters ({self.n_clusters}) must be > 1.\")\n",
        "        # init check\n",
        "        if isinstance(self.init, str) and self.init not in ('random', 'k-means++'):\n",
        "           raise ValueError(f\"init ({self.init}) must be 'random' or 'k-means++'.\")\n",
        "        # n_init check\n",
        "        if self.n_init < 1:\n",
        "           raise ValueError(f\"n_init ({self.n_init}) must be > 0.\")\n",
        "\n",
        "        # Attributes\n",
        "        self.labels_ = None          # Cluster labels (converged partition)\n",
        "        self.cluster_centers_ = None # Cluster centers (converged partition)\n",
        "        self.n_iter_ = None          # Number of iterations (until convergence)\n",
        "        self.sil_ = None             # silhouette (centroid-approximated) at converged partition\n",
        "\n",
        "        # history attributes\n",
        "        self.centers_history_ = None # Centroids across iterations\n",
        "        self.labels_history_ = None  # Assignments across iterations\n",
        "        self.sil_history_ = None     # Silhouette proxy across iterations\n",
        "        self.weights_history_ = None # Weights across iterations\n",
        "\n",
        "    def _initialization(self, X, n_clusters):\n",
        "        X = np.asarray(X)\n",
        "        if X.shape[0] < n_clusters:\n",
        "           raise ValueError(f\"n_clusters ({n_clusters}) can not exceed n_samples ({X.shape[0]}).\")\n",
        "\n",
        "        kmeans = KMeans(n_clusters=n_clusters,\n",
        "                        init=self.init,\n",
        "                        random_state=self.random_state,\n",
        "                        n_init=1,\n",
        "                        max_iter=1).fit(X)\n",
        "        centers = kmeans.cluster_centers_\n",
        "        labels = kmeans.labels_\n",
        "\n",
        "        # Retry if some clusters are empty in the initial assignment\n",
        "        if np.unique(labels).size < n_clusters:\n",
        "           max_retries = 10 # 10 retries at max\n",
        "           base_seed = self.random_state\n",
        "           for attempt in range(1, max_retries + 1):\n",
        "               seed = base_seed + attempt\n",
        "               km = KMeans(n_clusters=n_clusters,\n",
        "                           init=self.init,\n",
        "                           random_state=seed,\n",
        "                           n_init=1,\n",
        "                           max_iter=1).fit(X)\n",
        "               centers = km.cluster_centers_\n",
        "               labels = km.labels_\n",
        "               if np.unique(labels).size == n_clusters:\n",
        "                  break\n",
        "           else:\n",
        "               raise ValueError(\n",
        "                     f\"KMeans (1-iter) initialization produced empty clusters after {max_retries} retries. \"\n",
        "                     f\"Try a different random_state, or init='k-means++'.\")\n",
        "        return centers, labels\n",
        "\n",
        "    def _fit_once(self, X, n_clusters, previous_centers, w):\n",
        "        X = np.asarray(X)\n",
        "        w = np.asarray(w)\n",
        "        km = KMeans(\n",
        "             n_clusters=n_clusters,\n",
        "             init=previous_centers,\n",
        "             n_init=1,\n",
        "             max_iter=1,\n",
        "             random_state=self.random_state)\n",
        "        km.fit(X, sample_weight=w)\n",
        "\n",
        "        centers = km.cluster_centers_\n",
        "        labels = km.labels_\n",
        "        return centers, labels\n",
        "\n",
        "    def _reinit_empty_clusters(self, X, centers, labels, n_clusters):\n",
        "        \"\"\"\n",
        "        If some clusters are empty, reinitialize each empty cluster center to:\n",
        "          - the point in the (current) largest cluster that is farthest from its centroid\n",
        "        and move that point to the empty cluster (update labels) so it's not empty.\n",
        "        \"\"\"\n",
        "        X = np.asarray(X)\n",
        "        centers = np.asarray(centers, dtype=float)\n",
        "        labels = np.asarray(labels, dtype=int)\n",
        "\n",
        "        counts = np.bincount(labels, minlength=n_clusters)\n",
        "        empty = np.flatnonzero(counts == 0)\n",
        "        if empty.size == 0:\n",
        "            return centers, labels\n",
        "\n",
        "        used_idx = set()\n",
        "\n",
        "        for k_empty in empty:\n",
        "            # donor = largest cluster with at least 2 points (so we don't create a new empty)\n",
        "            donor_candidates = np.flatnonzero(counts > 1)\n",
        "\n",
        "            if donor_candidates.size == 0:\n",
        "                # Fallback: pick the point farthest from its nearest centroid overall\n",
        "                dist = euclidean_distances(X, centers, squared=False)\n",
        "                nearest = dist.min(axis=1)\n",
        "\n",
        "                order = np.argsort(-nearest)  # descending\n",
        "                idx = None\n",
        "                for j in order:\n",
        "                    j = int(j)\n",
        "                    if j not in used_idx:\n",
        "                        idx = j\n",
        "                        break\n",
        "                if idx is None:\n",
        "                    idx = int(order[0])\n",
        "            else:\n",
        "                donor = int(donor_candidates[np.argmax(counts[donor_candidates])])\n",
        "\n",
        "                members_all = np.flatnonzero(labels == donor)\n",
        "                members = members_all\n",
        "\n",
        "                # exclude already-used points if possible\n",
        "                if used_idx:\n",
        "                    used_arr = np.fromiter(used_idx, dtype=int, count=len(used_idx))\n",
        "                    mask = ~np.isin(members, used_arr)\n",
        "                    if np.any(mask):\n",
        "                        members = members[mask]\n",
        "                    else:\n",
        "                        members = members_all  # fallback: allow reuse if we must\n",
        "\n",
        "                # farthest donor member from donor centroid\n",
        "                d = np.linalg.norm(X[members] - centers[donor], axis=1)\n",
        "                idx = int(members[np.argmax(d)])\n",
        "\n",
        "            used_idx.add(idx)\n",
        "\n",
        "            # Move that point to the empty cluster and re-seed center at that point\n",
        "            old = int(labels[idx])\n",
        "            labels[idx] = int(k_empty)\n",
        "            centers[k_empty] = X[idx]\n",
        "\n",
        "            # Update counts bookkeeping\n",
        "            counts[old] -= 1\n",
        "            counts[k_empty] += 1\n",
        "\n",
        "        return centers, labels\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def sil_scores(X, labels, centers):\n",
        "        X = np.asarray(X, dtype=float)\n",
        "        labels = np.asarray(labels, dtype=int)\n",
        "        centers = np.asarray(centers, dtype=float)\n",
        "\n",
        "        if len(X) == 0:\n",
        "           raise ValueError(\"X is empty. Cannot compute silhouette scores.\")\n",
        "\n",
        "        n = X.shape[0]\n",
        "\n",
        "        # Squared distances to all centroids\n",
        "        D = euclidean_distances(X, centers, squared=True)\n",
        "\n",
        "        # Distance to own centroid (a: intra cluster distance proxy)\n",
        "        D_diag = D[np.arange(n), labels]  # a^2\n",
        "        a_vals = np.sqrt(D_diag)  # a\n",
        "\n",
        "        # Nearest other centroid distance (b: inter cluster distance)\n",
        "        D_others = D.copy()\n",
        "        D_others[np.arange(n), labels] = np.inf\n",
        "        b_sq = D_others.min(axis=1)  # b^2\n",
        "        b_vals = np.sqrt(b_sq)  # b\n",
        "\n",
        "        # Silhouette surrogate (b-a)/[max{a,b}+epsilon]\n",
        "        max_ab = np.maximum(np.maximum(a_vals, b_vals), 1e-12)\n",
        "        s_vals = (b_vals - a_vals) / max_ab\n",
        "\n",
        "        return s_vals, a_vals, b_vals\n",
        "\n",
        "    @staticmethod\n",
        "    def micro_sil(s_vals):\n",
        "        s_vals = np.asarray(s_vals, dtype=float)\n",
        "        if s_vals.size == 0:\n",
        "           return 0.0\n",
        "        return float(s_vals.mean())\n",
        "\n",
        "    @staticmethod\n",
        "    def macro_sil(s_vals, labels):\n",
        "        s_vals = np.asarray(s_vals, dtype=float)\n",
        "        labels = np.asarray(labels, dtype=int)\n",
        "\n",
        "        if s_vals.size == 0 or labels.size == 0:\n",
        "           return 0.0\n",
        "\n",
        "        uniq, inv = np.unique(labels, return_inverse=True)\n",
        "        if uniq.size == 0:\n",
        "           return 0.0\n",
        "        sum_per_cluster = np.bincount(inv, weights=s_vals)\n",
        "        cnt_per_cluster = np.bincount(inv)\n",
        "\n",
        "        valid = cnt_per_cluster > 0\n",
        "        if not np.any(valid):\n",
        "           return 0.0\n",
        "        cluster_means = sum_per_cluster[valid] / cnt_per_cluster[valid]\n",
        "        return float(cluster_means.mean())\n",
        "\n",
        "    def _weights(self, s_vals, temperature):\n",
        "        s_vals = np.asarray(s_vals, dtype=float)\n",
        "        weights = np.exp(s_vals * temperature)\n",
        "        return weights\n",
        "\n",
        "    def _KSil(self, X, n_clusters, max_iter):\n",
        "\n",
        "        # Initialize centroids\n",
        "        centers, labels = self._initialization(X, n_clusters)\n",
        "        tau = self.init_temperature # initial temperature\n",
        "        prev_score =  None\n",
        "\n",
        "        centers_history = [centers.copy()]\n",
        "        labels_history = [labels.copy()]\n",
        "        sil_history = []\n",
        "        weights_history = []\n",
        "\n",
        "        n_iter = 0\n",
        "\n",
        "        while n_iter < max_iter:\n",
        "\n",
        "            n_iter += 1\n",
        "\n",
        "            # Compute point-silhouette scores\n",
        "            sil_vals, a_vals, b_vals = KSil.sil_scores(X, labels, centers)\n",
        "            score = KSil.macro_sil(sil_vals, labels)\n",
        "\n",
        "            micro_sil = KSil.micro_sil(sil_vals)\n",
        "            sil_history.append(micro_sil)\n",
        "\n",
        "            # Update temperature\n",
        "            if prev_score is not None:\n",
        "               r = (score - prev_score) / max(1 - prev_score, 1e-12)\n",
        "\n",
        "               r = float(np.clip(r, -1.0, 1.0))\n",
        "\n",
        "               # data-driven bounds to avoid softmax saturation\n",
        "               counts = np.bincount(labels, minlength=n_clusters)\n",
        "               m_max = int(max(counts.max(), 2))\n",
        "               L     = float(np.sqrt(2.0 * np.log(m_max)))\n",
        "               z_max = (m_max - 1) / m_max\n",
        "               tau_min, tau_max = 1e-12, L / max(z_max, 1e-8)\n",
        "\n",
        "               # multiplicative update (no logs needed)\n",
        "               eta = self.learning_rate # default: 0.2 (small stable learning rate)\n",
        "\n",
        "               # Update temperature based on the rate of change of the silhouette objective\n",
        "               tau = float(np.clip(tau * np.exp(eta * r), tau_min, tau_max))\n",
        "\n",
        "            # store for next iteration’s drift calc\n",
        "            prev_score = score\n",
        "\n",
        "            # Retain previous centroids for convergence checking\n",
        "            previous_centers = centers.copy()\n",
        "\n",
        "            # Compute weights based on silhouette scores\n",
        "            weights = self._weights(sil_vals, tau)\n",
        "\n",
        "            weights_history.append(weights.copy())\n",
        "\n",
        "            # Update centroids and assignments\n",
        "            centers, labels = self._fit_once(X, n_clusters, previous_centers, weights)\n",
        "\n",
        "            # If any cluster became empty, reinitialize it deterministically\n",
        "            counts = np.bincount(labels, minlength=n_clusters)\n",
        "            if np.any(counts == 0):\n",
        "                centers, labels = self._reinit_empty_clusters(X, centers, labels, n_clusters)\n",
        "\n",
        "\n",
        "            centers_history.append(centers.copy())\n",
        "            labels_history.append(labels.copy())\n",
        "\n",
        "            avg_move = np.linalg.norm(centers - previous_centers, axis=1).mean()\n",
        "\n",
        "            # Centroid stability\n",
        "            if avg_move < self.tol:\n",
        "               break\n",
        "\n",
        "        return centers, labels, n_iter, sil_history, centers_history, labels_history, weights_history\n",
        "\n",
        "    def fit(self, X):\n",
        "        \"\"\"\n",
        "        Run KSil on X and store the converged partition.\n",
        "        X: array-like, shape (n_samples, n_features)\n",
        "        \"\"\"\n",
        "        X_arr = X.values if hasattr(X, \"values\") else np.asarray(X, dtype=float)\n",
        "\n",
        "        if self.n_init == 1:\n",
        "           (centers,\n",
        "           labels,\n",
        "           n_iter,\n",
        "           sil_history,\n",
        "           centers_history,\n",
        "           labels_history,\n",
        "           weights_history) = self._KSil(X_arr, self.n_clusters, self.max_iter)\n",
        "        else:\n",
        "           base_seed = self.random_state\n",
        "           seeds = [int(base_seed) + i for i in range(self.n_init)]\n",
        "\n",
        "           # Helper: directly call _KSil with a seed\n",
        "           def _run_one(seed):\n",
        "               self.random_state = seed\n",
        "               return self._KSil(X_arr, self.n_clusters, self.max_iter)\n",
        "\n",
        "           if self.n_jobs in (None, 1):\n",
        "              results = [_run_one(seed) for seed in seeds]\n",
        "           else:\n",
        "              results = Parallel(n_jobs=self.n_jobs)(delayed(_run_one)(seed) for seed in seeds)\n",
        "\n",
        "           # Pick best run by final silhouette\n",
        "           best_idx = None\n",
        "           best_sil = -np.inf\n",
        "\n",
        "           for i, res in enumerate(results):\n",
        "               (_, _, _, sil_history_i,\n",
        "               _, _, _) = res\n",
        "               if sil_history_i:\n",
        "                  final_sil_i = sil_history_i[-1]\n",
        "               else:\n",
        "                  final_sil_i = -np.inf\n",
        "               if final_sil_i > best_sil:\n",
        "                   best_sil = final_sil_i\n",
        "                   best_idx = i\n",
        "\n",
        "           (centers,\n",
        "           labels,\n",
        "           n_iter,\n",
        "           sil_history,\n",
        "           centers_history,\n",
        "           labels_history,\n",
        "           weights_history) = results[best_idx]\n",
        "\n",
        "           self.random_state = base_seed # restore base random_state\n",
        "\n",
        "        self.cluster_centers_ = centers\n",
        "        self.labels_ = labels\n",
        "        self.n_iter_ = n_iter\n",
        "\n",
        "        self.sil_history_ = sil_history\n",
        "        self.sil_ = sil_history[-1] if sil_history else None\n",
        "        self.centers_history_ = centers_history\n",
        "        self.labels_history_ = labels_history\n",
        "        self.weights_history_ = weights_history\n",
        "\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        Assign new points to the nearest learned centroid.\n",
        "        \"\"\"\n",
        "        if self.cluster_centers_ is None:\n",
        "           raise ValueError(\"KSil model is not fitted yet. Call '.fit(...)' first.\")\n",
        "\n",
        "        X_arr = X.values if hasattr(X, \"values\") else np.asarray(X, dtype=float)\n",
        "        dist_matrix = euclidean_distances(X_arr, self.cluster_centers_, squared=True)\n",
        "        labels = np.argmin(dist_matrix, axis=1)\n",
        "        return labels.astype(int)\n",
        "\n",
        "    def transform(self, X):\n",
        "        \"\"\"\n",
        "        Return distances of each sample to each centroid.\n",
        "        \"\"\"\n",
        "        if self.cluster_centers_ is None:\n",
        "           raise ValueError(\"KSil model is not fitted yet. Call '.fit(...)' first.\")\n",
        "\n",
        "        X_arr = X.values if hasattr(X, \"values\") else np.asarray(X, dtype=float)\n",
        "        distances = euclidean_distances(X_arr, self.cluster_centers_, squared=False)\n",
        "        return distances\n",
        "\n",
        "    def fit_predict(self, X):\n",
        "        \"\"\"\n",
        "        Equivalent to: fit(X); return labels_.\n",
        "        \"\"\"\n",
        "        self.fit(X)\n",
        "        return self.labels_\n",
        "\n",
        "    def fit_transform(self, X):\n",
        "        \"\"\"\n",
        "        Equivalent to: fit(X); return transform(X).\n",
        "        \"\"\"\n",
        "        self.fit(X)\n",
        "        return self.transform(X)"
      ],
      "metadata": {
        "id": "m9iEYdtSHrUD"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Example"
      ],
      "metadata": {
        "id": "-YpE-cqtKAyt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_blobs\n",
        "\n",
        "X, y_true = make_blobs(n_samples=31, centers=2, cluster_std=0.60, random_state=7)\n",
        "n_clusters = 3\n",
        "labels = y_true.copy()\n",
        "centers = np.zeros((n_clusters, X.shape[1]))\n",
        "centers[0] = X[labels == 0].mean(axis=0)\n",
        "centers[1] = X[labels == 1].mean(axis=0)\n",
        "centers[2] = np.array([999.0, 999.0])\n",
        "\n",
        "print(\"Before:\", np.bincount(labels, minlength=n_clusters))\n",
        "\n",
        "m = KSil_ecr(n_clusters=n_clusters)\n",
        "centers2, labels2 = m._reinit_empty_clusters(X, centers, labels, n_clusters)\n",
        "\n",
        "print(\"After :\", np.bincount(labels2, minlength=n_clusters))\n",
        "print(\"New center for empty cluster was set to a real data point:\", centers2[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kxlhui6xJk83",
        "outputId": "1b93b72d-7745-4660-f089-409374ea9a0c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before: [16 15  0]\n",
            "After : [15 15  1]\n",
            "New center for empty cluster was set to a real data point: [-8.70611818  6.81581918]\n"
          ]
        }
      ]
    }
  ]
}